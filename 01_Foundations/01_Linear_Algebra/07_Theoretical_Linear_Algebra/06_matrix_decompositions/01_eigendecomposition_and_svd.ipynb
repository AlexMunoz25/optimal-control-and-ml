{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26dfcd3",
   "metadata": {},
   "source": [
    "### 1.1.7.6.1. Eigendecomposition and SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a534bf",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Eigendecomposition:} \\quad A = Q \\Lambda Q^{-1}, \\quad \\text{normal: } A = O \\Lambda O^{\\mathsf{T}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{SVD:} \\quad A = U \\Sigma V^{\\mathsf{T}}, \\quad \\sigma_i = \\sqrt{\\lambda_i(A^{\\mathsf{T}} A)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Low-rank approximation:} \\quad A_k = \\sum_{i=1}^{k} \\sigma_i \\, \\mathbf{u}_i \\mathbf{v}_i^{\\mathsf{T}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2fe38b",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**Eigendecomposition** $A = Q\\Lambda Q^{-1}$ expresses a square matrix through its eigenbasis. For symmetric matrices, eigenvectors are orthogonal: $A = O\\Lambda O^T$. The eigenbasis is the \"natural\" basis where $A$ acts as simple scaling.\n",
    "\n",
    "**SVD** generalizes eigendecomposition to any $m \\times n$ matrix. It decomposes $A$ into three steps: rotate ($V^T$), scale ($\\Sigma$), rotate ($U$). The singular values $\\sigma_i$ are the square roots of eigenvalues of $A^T A$.\n",
    "\n",
    "SVD enables **low-rank approximation**: truncating to the top $k$ singular values gives the best rank-$k$ approximation (Eckart‚ÄìYoung theorem). This underpins PCA and data compression.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix} \\quad \\Rightarrow \\quad \\lambda_1 = 3, \\; \\lambda_2 = 1, \\quad \\sigma_1 = 3, \\; \\sigma_2 = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa17271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix_a = np.array([[2.0, 1.0], [1.0, 2.0]])\n",
    "\n",
    "eigenvalues, eigenvectors_q = np.linalg.eig(matrix_a)\n",
    "lambda_diag = np.diag(eigenvalues)\n",
    "reconstructed_eigen = eigenvectors_q @ lambda_diag @ np.linalg.inv(eigenvectors_q)\n",
    "print(\"--- Eigendecomposition ---\")\n",
    "print(f\"Eigenvalues: {np.round(eigenvalues, 4)}\")\n",
    "print(f\"Q Lambda Q^-1 == A: {np.allclose(reconstructed_eigen, matrix_a)}\")\n",
    "\n",
    "left_u, singular_values, right_vt = np.linalg.svd(matrix_a)\n",
    "sigma_matrix = np.diag(singular_values)\n",
    "reconstructed_svd = left_u @ sigma_matrix @ right_vt\n",
    "print(\"\\n--- SVD ---\")\n",
    "print(f\"Singular values: {np.round(singular_values, 4)}\")\n",
    "print(f\"U Sigma V^T == A: {np.allclose(reconstructed_svd, matrix_a)}\")\n",
    "\n",
    "print(\"\\n--- Low-rank Approximation (random 5x5, rank 2) ---\")\n",
    "rng = np.random.default_rng(42)\n",
    "large_matrix = rng.standard_normal((5, 5))\n",
    "left_u_lg, singular_lg, right_vt_lg = np.linalg.svd(large_matrix)\n",
    "rank_k = 2\n",
    "approximation = left_u_lg[:, :rank_k] @ np.diag(singular_lg[:rank_k]) @ right_vt_lg[:rank_k, :]\n",
    "error = np.linalg.norm(large_matrix - approximation, \"fro\")\n",
    "print(f\"Frobenius error (rank-{rank_k}): {round(error, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1dd5e5",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[üìò Savov, I. (2016). *No Bullshit Guide to Linear Algebra*, Section 7.6 \"Matrix Decompositions.\"](https://minireference.com/static/excerpts/noBSLA_v2_preview.pdf)\n",
    "\n",
    "---\n",
    "\n",
    "[‚¨ÖÔ∏è Previous: Gram‚ÄìSchmidt Orthogonalization](../05_gram_schmidt/01_gram_schmidt.ipynb) | [Next: LU and Cholesky Decomposition ‚û°Ô∏è](./02_lu_and_cholesky.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
