{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f7f331",
   "metadata": {},
   "source": [
    "### 1.1.7.1.14. Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff08162",
   "metadata": {},
   "source": [
    "$$\n",
    "A^n = Q \\Lambda^n Q^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2ba1ad",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "The eigendecomposition is a building block for many scientific methods. In statistics, PCA eigendecomposes the covariance matrix to find principal components. Google's PageRank algorithm finds the dominant eigenvector of the hyperlink matrix. In quantum mechanics, eigenvalues of the Hamiltonian operator correspond to energy levels.\n",
    "\n",
    "A fundamental computational technique is **power iteration**: repeatedly multiplying a random vector by $A$ and normalizing converges to the dominant eigenvector (the one associated with the largest eigenvalue in absolute value).\n",
    "\n",
    "**Example:**\n",
    "\n",
    "For\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Starting from a random vector $\\vec{v}_0$, iterate $\\vec{v}_{k+1} = \\frac{A\\vec{v}_k}{\\|A\\vec{v}_k\\|}$ until convergence. The result approaches the eigenvector corresponding to the largest eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2ecb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power iteration result:\n",
      "  Dominant eigenvector: [0.525731 0.850651]\n",
      "  Dominant eigenvalue: 3.618034\n",
      "\n",
      "np.linalg.eig result:\n",
      "  Dominant eigenvector: [-0.525731 -0.850651]\n",
      "  Dominant eigenvalue: 3.618034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix_a = np.array([[2, 1],\n",
    "                     [1, 3]])\n",
    "\n",
    "np.random.seed(42)\n",
    "current_vector = np.random.rand(2)\n",
    "current_vector = current_vector / np.linalg.norm(current_vector)\n",
    "\n",
    "num_iterations = 20\n",
    "for iteration in range(num_iterations):\n",
    "    next_vector = matrix_a @ current_vector\n",
    "    estimated_eigenvalue = np.dot(next_vector, current_vector)\n",
    "    current_vector = next_vector / np.linalg.norm(next_vector)\n",
    "\n",
    "eigenvalues_exact, eigenvectors_exact = np.linalg.eig(matrix_a)\n",
    "dominant_index = np.argmax(np.abs(eigenvalues_exact))\n",
    "\n",
    "print(\"Power iteration result:\")\n",
    "print(\"  Dominant eigenvector:\", np.round(current_vector, 6))\n",
    "print(\"  Dominant eigenvalue:\", np.round(estimated_eigenvalue, 6))\n",
    "print(\"\\nnp.linalg.eig result:\")\n",
    "print(\"  Dominant eigenvector:\", np.round(eigenvectors_exact[:, dominant_index], 6))\n",
    "print(\"  Dominant eigenvalue:\", np.round(eigenvalues_exact[dominant_index], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21dfdc3",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[üìò Savov, I. (2016). *No Bullshit Guide to Linear Algebra*, Section 7.1](https://minireference.com/)\n",
    "\n",
    "---\n",
    "\n",
    "[‚¨ÖÔ∏è Previous: Matrix Power Series](./13_matrix_power_series.ipynb) | [Next: Special Types of Matrices ‚û°Ô∏è](../02_special_types_of_matrices/01_special_types_of_matrices.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
